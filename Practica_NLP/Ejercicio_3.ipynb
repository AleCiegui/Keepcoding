{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Etapa de entrenamiento y testeo de un modelo de análisis de sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "# Paso 1: Representación con Bag of Words (BoW)\n",
    "###############################################\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Para cargar el CSV\n",
    "df = pd.read_csv(\"./Musical_Instruments_preprocessed.csv\")\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Balancear resviews\n",
    "\n",
    "# Definir variables X (texto) e y (clase)\n",
    "X = df[\"review_clean\"]  # Usaremos el texto limpio para el modelo\n",
    "y = df[\"sentiment\"]     # Etiquetas (0 = negativo, 1 = positivo)\n",
    "\n",
    "# Aplicar undersampling para igualar el número de positivos y negativos\n",
    "undersampler = RandomUnderSampler(sampling_strategy=1.0, random_state=42)\n",
    "X_resampled, y_resampled = undersampler.fit_resample(X.values.reshape(-1, 1), y)\n",
    "\n",
    "# Convertir X_resampled a DataFrame\n",
    "df_balanced = pd.DataFrame({\"review_clean\": X_resampled.flatten(), \"sentiment\": y_resampled})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Distribución en Train:\n",
      " sentiment\n",
      "positive    0.500006\n",
      "negative    0.499994\n",
      "Name: proportion, dtype: float64\n",
      "📌 Distribución en Test:\n",
      " sentiment\n",
      "negative    0.500022\n",
      "positive    0.499978\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Variables de entrada y salida\n",
    "X = df_balanced[\"review_clean\"]  # Texto limpio\n",
    "y = df_balanced[\"sentiment\"]      # Etiquetas (0 = negativo, 1 = positivo)\n",
    "\n",
    "# División en 80% entrenamiento y 20% prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Verificar distribución después del split\n",
    "print(\"📌 Distribución en Train:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"📌 Distribución en Test:\\n\", y_test.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Matriz BoW generada con tamaño: (113582, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Reemplazar valores NaN en la columna review_clean\n",
    "df_balanced[\"review_clean\"] = df_balanced[\"review_clean\"].fillna(\"\")\n",
    "\n",
    "df_balanced.to_csv(\"./Musical_Instruments_balanced.csv\", index=False)\n",
    "\n",
    "# Crear vectorizador BoW con las 5000 palabras más frecuentes\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "\n",
    "# Aplicar transformación al texto\n",
    "X_bow = vectorizer.fit_transform(df_balanced[\"review_clean\"])\n",
    "\n",
    "# Mostrar tamaño de la matriz resultante\n",
    "print(f\"📌 Matriz BoW generada con tamaño: {X_bow.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alejandro Catalan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Modelos entrenados correctamente.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# División en 80% entrenamiento y 20% prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, df_balanced[\"sentiment\"], test_size=0.2, random_state=42, stratify=df_balanced[\"sentiment\"])\n",
    "\n",
    "# Modelo 1: Regresión Logística\n",
    "logistic_model = LogisticRegression(class_weight=\"balanced\", max_iter=200)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Modelo 2: Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"📌 Modelos entrenados correctamente.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Matriz Word2Vec generada con tamaño: (113582, 100)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "df_balanced[\"tokens\"] = df[\"tokens\"]\n",
    "\n",
    "# Entrenar modelo Word2Vec con los tokens limpios\n",
    "word2vec_model = Word2Vec(sentences=df_balanced[\"tokens\"], vector_size=100, window=5, min_count=5, workers=4)\n",
    "\n",
    "# Obtener el tamaño de los embeddings \n",
    "vector_size = word2vec_model.vector_size\n",
    "\n",
    "# Función para convertir una review en un \n",
    "# vector promedio de sus palabras\n",
    "def get_review_vector(review_tokens, model):\n",
    "    vectors = [model.wv[word] for word in review_tokens if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(vector_size)\n",
    "\n",
    "# Convertir todas las reviews en vectores\n",
    "X_w2v = np.array([get_review_vector(tokens, word2vec_model) for tokens in df_balanced[\"tokens\"]])\n",
    "\n",
    "# Mostrar tamaño de la matriz Word2Vec\n",
    "print(f\"📌 Matriz Word2Vec generada con tamaño: {X_w2v.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Modelo con Word2Vec entrenado correctamente.\n"
     ]
    }
   ],
   "source": [
    "# División en 80% entrenamiento y 20% prueba\n",
    "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(X_w2v, df_balanced[\"sentiment\"], test_size=0.2, random_state=42, stratify=df_balanced[\"sentiment\"])\n",
    "\n",
    "# Modelo con Word2Vec\n",
    "logistic_w2v = LogisticRegression(class_weight=\"balanced\", max_iter=200)\n",
    "logistic_w2v.fit(X_train_w2v, y_train_w2v)\n",
    "\n",
    "print(\"📌 Modelo con Word2Vec entrenado correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Resultados de Word2Vec:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.61      0.59     11359\n",
      "    positive       0.58      0.54      0.56     11358\n",
      "\n",
      "    accuracy                           0.58     22717\n",
      "   macro avg       0.58      0.58      0.58     22717\n",
      "weighted avg       0.58      0.58      0.58     22717\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predicciones con Word2Vec\n",
    "y_pred_w2v = logistic_w2v.predict(X_test_w2v)\n",
    "\n",
    "# Evaluación de Word2Vec\n",
    "print(\"📌 Resultados de Word2Vec:\")\n",
    "print(classification_report(y_test_w2v, y_pred_w2v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Resultados de Regresión Logística:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.77      0.79     11359\n",
      "    positive       0.78      0.82      0.80     11358\n",
      "\n",
      "    accuracy                           0.80     22717\n",
      "   macro avg       0.80      0.80      0.80     22717\n",
      "weighted avg       0.80      0.80      0.80     22717\n",
      "\n",
      "📌 Resultados de Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.81      0.78     11359\n",
      "    positive       0.79      0.73      0.76     11358\n",
      "\n",
      "    accuracy                           0.77     22717\n",
      "   macro avg       0.77      0.77      0.77     22717\n",
      "weighted avg       0.77      0.77      0.77     22717\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicciones en Test\n",
    "y_pred_logistic = logistic_model.predict(X_test)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluación de Regresión Logística\n",
    "print(\"📌 Resultados de Regresión Logística:\")\n",
    "print(classification_report(y_test, y_pred_logistic))\n",
    "\n",
    "# Evaluación de Random Forest\n",
    "print(\"📌 Resultados de Random Forest:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Modelos guardados en ./models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "# Definir carpeta donde se guardarán los modelos\n",
    "model_dir = \"./models\"\n",
    "os.makedirs(model_dir, exist_ok=True)  # Crear la carpeta si no existe\n",
    "\n",
    "# Definir nombres de archivos\n",
    "logistic_file = os.path.join(model_dir, \"vd_logistic_bow.pkl\")\n",
    "rf_file = os.path.join(model_dir, \"vd_random_forest_bow.pkl\")\n",
    "w2v_file = os.path.join(model_dir, \"vd_logistic_word2vec.pkl\")\n",
    "\n",
    "# Guardar modelos\n",
    "joblib.dump(logistic_model, logistic_file)\n",
    "joblib.dump(rf_model, rf_file)\n",
    "joblib.dump(logistic_w2v, w2v_file)\n",
    "\n",
    "print(f\"📌 Modelos guardados en {model_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
